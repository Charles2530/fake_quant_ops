#!/usr/bin/env python3
"""
MXFP Scaling Test Tool
Tests different scaling strategies for MXFP quantization and evaluates their impact on accuracy.
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import argparse
from pathlib import Path
import sys
import os
import logging
from datetime import datetime

# Add the parent directory to path to import mxfp module
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
# import pdb;pdb.set_trace()

from quant.ops.mxfp import _quantize_mx, _get_format_params, ElemFormat,_shared_exponents

def quantize_with_fixed_scale(input_tensor, elem_format, scale_bits, scale_exp,
                             ebits, mbits, max_norm, axes=None, block_size=0):
    from quant.ops.mxfp import (
        _quantize_elemwise_core, _reshape_to_blocks, _undo_reshape_to_blocks,
        _get_min_norm, FP32_MIN_NORMAL
    )
    from utils.saver.mxfp_saver import _analyze_overflow_underflow_before_quantization
    
    A = input_tensor.clone()
    
    # Make sure axes is a list of non-negative numbers (same as _quantize_mx)
    if axes is None:
        axes = []
    else:
        axes = [axes] if type(axes) == int else axes
        axes = [x + A.ndim if x < 0 else x for x in axes]

    ebits, mbits, emax, max_norm, _ = _get_format_params(elem_format)

    if block_size > 0:
        A_reshaped, axes, orig_shape, padded_shape = _reshape_to_blocks(
            A, axes, block_size
        )
    else:
        A_reshaped = A

    shared_exp_axes = [x + 1 for x in axes] if block_size > 0 else axes
    shared_exp = _shared_exponents(
        A_reshaped, method=shared_exp_method, axes=shared_exp_axes, ebits=0,elem_format=elem_format, 
        minus_exp=minus_exp, heuristic_level=heuristic_level,
    )

    if flush_fp32_subnorms:
        A_reshaped = A_reshaped * (shared_exp > -FP32_EXPONENT_BIAS).type(A.dtype)

    shared_exp = shared_exp - emax
    
    # Clamp shared_exp to scale_bits range (same as _quantize_mx lines 426-428)
    scale_emax = 2**(scale_bits-1) - 1
    shared_exp[shared_exp > scale_emax] = float("NaN")
    shared_exp[shared_exp < -scale_emax] = -scale_emax
    
    # ========== Test with scale_exp ==========
    # Apply scaling (same as _quantize_mx line 430)
    q_A = A / (2**shared_exp)
    
    # Quantize element-wise (same as _quantize_mx lines 433-435)
    q_A = _quantize_elemwise_core(
        q_A, mbits, ebits, max_norm, round='nearest',
        allow_denorm=True, saturate_normals=True
    )
    
    # Undo scaling (same as _quantize_mx line 437)
    q_A = q_A * (2**shared_exp)
    
    # Calculate MSE per block with A and q_A
    if block_size > 0:
        # Calculate squared error
        squared_error = (A - q_A) ** 2
        # Calculate MSE per block by averaging over block_size dimensions
        # Use shared_exp_axes which correspond to the block dimensions
        # (shared_exp_axes = [x + 1 for x in axes] when block_size > 0)
        mse_per_block = squared_error
        for axis in shared_exp_axes:
            mse_per_block = torch.mean(mse_per_block, dim=axis, keepdim=True)
        # Calculate overall MSE from per-block MSE
        mse_scale = torch.mean(mse_per_block).item()
    else:
        # No blocks, calculate overall MSE
        mse_scale = torch.mean((A - q_A) ** 2).item()
    
    # ========== Test with scale_exp - 1 (half_scale) ==========
    # Create half_scale shared_exp
    shared_exp_half = shared_exp - 1
    
    # Clamp again to ensure it's within range
    shared_exp_half[shared_exp_half > scale_emax] = float("NaN")
    shared_exp_half[shared_exp_half < -scale_emax] = -scale_emax
    
    # Apply scaling with half_scale
    q_A_half = A / (2**shared_exp_half)
    import pdb;pdb.set_trace()
    
    # Quantize element-wise
    q_A_half = _quantize_elemwise_core(
        q_A_half, mbits, ebits, max_norm, round='nearest',
        allow_denorm=True, saturate_normals=True
    )
    
    # Undo scaling
    q_A_half = q_A_half * (2**shared_exp_half)
    
    # Calculate MSE per block with A and q_A_half
    if block_size > 0:
        # Calculate squared error
        squared_error_half = (A - q_A_half) ** 2
        # Calculate MSE per block by averaging over block_size dimensions
        mse_per_block_half = squared_error_half
        for axis in shared_exp_axes:
            mse_per_block_half = torch.mean(mse_per_block_half, dim=axis, keepdim=True)
        # Calculate overall MSE from per-block MSE
        mse_half_scale = torch.mean(mse_per_block_half).item()
    else:
        # No blocks, calculate overall MSE
        mse_half_scale = torch.mean((A - q_A_half) ** 2).item()
    
    return {
        'mse_scale': mse_scale,
        'mse_half_scale': mse_half_scale,
    }


def main():
    """Main function for MXFP scaling test."""
    parser = argparse.ArgumentParser(description='Test different scaling strategies for MXFP quantization')
    parser.add_argument('--input_tensor', default='data/bf16/20250923_100142_0001_iter000_linear_L1_forward_pre_linear_bf16_rank00_group000_input.pt', help='Path to input tensor file (.pt)')
    parser.add_argument('--elem-format', default='fp4_e2m1', 
                        choices=['fp8_e4m3', 'fp8_e5m2', 'fp4_e2m1', 'fp6_e3m2', 'fp6_e2m3'],
                        help='Element format for quantization (default: fp8_e4m3)')
    parser.add_argument('--scale-bits', type=int, default=8,
                        help='Number of scale bits (default: 8)')
    parser.add_argument('--max-scale-exp', type=int, default=10,
                        help='Maximum scale exponent (default: auto-calculated from tensor max if using default value)')
    parser.add_argument('--min-scale-exp', type=int, default=-10,
                        help='Minimum scale exponent (default: auto-calculated from tensor min if using default value)')
    parser.add_argument('--block-size', type=int, default=32,
                        help='Block size for tiling (default: 32, use 0 for no tiling)')
    parser.add_argument('--axes', type=int, default=-1,
                        help='Axes for shared exponent calculation (default: -1)')
    parser.add_argument('--no-plots', action='store_true',
                        help='Skip generating plots')
    
    args = parser.parse_args()

    try:
        # Load tensor
        input_tensor = torch.load(args.input_tensor, map_location='cpu')['tensor']
        
        if not isinstance(input_tensor, torch.Tensor):
            print(f"❌ Error: File does not contain a torch.Tensor")
            return 1
        
        print(f"Tensor shape: {input_tensor.shape}")
        print(f"Tensor dtype: {input_tensor.dtype}")
        print(f"Tensor range: [{input_tensor.min().item():.6f}, {input_tensor.max().item():.6f}]")
        
        # Get format parameters
        ebits, mbits, emax, max_norm, _ = _get_format_params(args.elem_format)
        print(f"\nElement format: {args.elem_format}")
        print(f"  ebits: {ebits}, mbits: {mbits}, max_norm: {max_norm}")
        
        # Convert axes to list if needed
        axes = args.axes if isinstance(args.axes, list) else [args.axes] if args.axes is not None else None
        
        # Determine scale_exp to test
        # Use max_scale_exp as the primary scale_exp, and test scale_exp - 1 as half_scale
        scale_exp = args.max_scale_exp
        
        print(f"\nTesting scale_exp = {scale_exp} vs scale_exp - 1 = {scale_exp - 1}")
        print("=" * 80)
        
        result = quantize_with_fixed_scale(
            input_tensor=input_tensor,
            elem_format=args.elem_format,
            scale_bits=args.scale_bits,
            scale_exp=scale_exp,
            ebits=ebits,
            mbits=mbits,
            max_norm=max_norm,
            axes=axes,
            block_size=args.block_size
        )
        
        # Print results
        print(f"\nResults:")
        print(f"  MSE (scale_exp={scale_exp}):     {result['mse_scale']:.6e}")
        print(f"  MSE (scale_exp={scale_exp-1}):  {result['mse_half_scale']:.6e}")
        if result['mse_scale'] > 0:
            improvement = ((result['mse_scale'] - result['mse_half_scale']) / result['mse_scale'] * 100)
            print(f"  Improvement: {improvement:.2f}%")
            if result['mse_half_scale'] < result['mse_scale']:
                print(f"  ✅ Half scale (scale_exp - 1) has better MSE")
            else:
                print(f"  ✅ Original scale has better MSE")
        
        return 0
        
    except Exception as e:
        print(f"❌ Error: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    exit(main())
